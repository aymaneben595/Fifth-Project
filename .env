# ----------------------------------------------------------------------
# CAR SALES ANALYTICS PIPELINE CONFIGURATION (.env file)
# This file stores the secure settings and parameters for the Python script
# (elt_pipeline.py) so it can connect to the database and run reports.
# ----------------------------------------------------------------------

# -------------------------
# DATABASE CONNECTION SETTINGS
# (These define how the script logs into the PostgreSQL database)
# -------------------------

# The database username used to log in.
PG_USER=postgres
# The password for the specified user (Keep this strictly confidential!).
PG_PASS=Aymaneb595.
# The network address where the database lives (usually your own computer for development).
PG_HOST=localhost
# The port number used for communication (standard PostgreSQL port).
PG_PORT=5432
# The name of the main database where the car sales data is stored.
PG_DB=fdb
# The specific area (schema) within the database where our clean 'analytics' tables reside.
PG_SCHEMA=public


# -------------------------
# PIPELINE OUTPUT SETTINGS
# (These define where the final reports and logs will be saved)
# -------------------------

# The folder where the final clean CSV reports (e.g., KPI summary, Top Customers) will be exported.
OUTPUT_DIR=./outputs
# The folder designated for storing the script's operational logs (when it started, finished, or had errors).
LOG_DIR=./logs

# -------------------------
# DATA QUALITY & VALIDATION RULES
# (These are rules to ensure the pipeline is running on sufficient and high-quality data)
# -------------------------

# MAXIMUM ACCEPTABLE NULL RATE: If a critical column (like 'price') is missing data for more than 40% (0.4) of the rows, 
# the pipeline will flag a major data quality issue.
MAX_NULL_RATE=0.4
# MINIMUM REQUIRED ROWS: The pipeline must process at least 1 row of data to be considered a successful run. 
# This prevents running reports on completely empty datasets.
MIN_ROWS=1
